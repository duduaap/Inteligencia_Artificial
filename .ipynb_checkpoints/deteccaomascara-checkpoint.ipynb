{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90b67225",
   "metadata": {},
   "source": [
    "## Analise de pessoas com e sem mÃ¡scara usando o Keras "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5b9853",
   "metadata": {},
   "source": [
    "Se baseando no mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99a2333d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_datasets in c:\\users\\misael\\anaconda3\\lib\\site-packages (4.5.2)\n",
      "Requirement already satisfied: protobuf>=3.12.2 in c:\\users\\misael\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (3.19.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\misael\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (4.62.3)\n",
      "Requirement already satisfied: dill in c:\\users\\misael\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (0.3.4)\n",
      "Requirement already satisfied: promise in c:\\users\\misael\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (2.3)\n",
      "Requirement already satisfied: termcolor in c:\\users\\misael\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\misael\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.20.3)\n",
      "Requirement already satisfied: absl-py in c:\\users\\misael\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.0.0)\n",
      "Requirement already satisfied: tensorflow-metadata in c:\\users\\misael\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.6.0)\n",
      "Requirement already satisfied: six in c:\\users\\misael\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.16.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\misael\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (2.26.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\misael\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\misael\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\misael\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\misael\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (1.26.7)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in c:\\users\\misael\\anaconda3\\lib\\site-packages (from tensorflow-metadata->tensorflow_datasets) (1.54.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\misael\\anaconda3\\lib\\site-packages (from tqdm->tensorflow_datasets) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_datasets\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761b2352",
   "metadata": {},
   "source": [
    "## Carregando as imagens para testes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9934e18",
   "metadata": {},
   "source": [
    "Carregando as imagens usando o Keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e700f63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1364e37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5112cfdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1376 files belonging to 2 classes.\n",
      "Using 344 files for validation.\n",
      "Found 1376 files belonging to 2 classes.\n",
      "Using 1032 files for training.\n"
     ]
    }
   ],
   "source": [
    "seed_salva=random.randint(60, 120000)\n",
    "(dt_validation)=tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"./dataset/dataset\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(256, 256),\n",
    "    shuffle=True,\n",
    "    seed=seed_salva,\n",
    "    validation_split=0.25,\n",
    "    subset=\"validation\",\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    ")\n",
    "\n",
    "(dt_training)=tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"./dataset/dataset\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(256, 256),\n",
    "    shuffle=True,\n",
    "    seed=seed_salva,\n",
    "    validation_split=0.25,\n",
    "    subset=\"training\",\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "547b6418",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24af7fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "912e8891",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(256, 256,3)),\n",
    "  tf.keras.layers.Dense(512,activation=\"relu\",input_shape=(256,256)),\n",
    "  tf.keras.layers.Dense(1,activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "460f63ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 196608)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               100663808 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100,664,321\n",
      "Trainable params: 100,664,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4117bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635bac6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "33/33 [==============================] - 12s 359ms/step - loss: 9921.9199 - accuracy: 0.6764 - val_loss: 891.1254 - val_accuracy: 0.8285\n",
      "Epoch 2/25\n",
      "33/33 [==============================] - 12s 357ms/step - loss: 1828.8040 - accuracy: 0.7636 - val_loss: 620.1693 - val_accuracy: 0.8547\n",
      "Epoch 3/25\n",
      "33/33 [==============================] - 12s 357ms/step - loss: 884.4332 - accuracy: 0.8566 - val_loss: 315.3434 - val_accuracy: 0.9041\n",
      "Epoch 4/25\n",
      "33/33 [==============================] - 12s 357ms/step - loss: 585.8895 - accuracy: 0.8847 - val_loss: 6732.3794 - val_accuracy: 0.5378\n",
      "Epoch 5/25\n",
      "17/33 [==============>...............] - ETA: 5s - loss: 1458.7377 - accuracy: 0.8199"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    dt_training,\n",
    "    epochs=25,\n",
    "    validation_data=dt_validation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd3539f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedda492",
   "metadata": {},
   "outputs": [],
   "source": [
    "image=tf.keras.preprocessing.image.load_img(\n",
    "   \"./eu.jpg\", grayscale=False, color_mode=\"rgb\", target_size=(256,256), interpolation=\"nearest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6507c26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019ee0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "input_arr = np.array([input_arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedd4018",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(input_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a740b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ffcfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ce9797",
   "metadata": {},
   "outputs": [],
   "source": [
    "image2=tf.keras.preprocessing.image.load_img(\n",
    "   \"./eu_sem_mascara.jpg\", grayscale=False, color_mode=\"rgb\", target_size=(256,256), interpolation=\"nearest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182da740",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_arr = tf.keras.preprocessing.image.img_to_array(image2)\n",
    "input_arr = np.array([input_arr])\n",
    "predictions2=model.predict(input_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42276f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "image2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d3f1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97552f7a",
   "metadata": {},
   "source": [
    "## Modelo Convolucional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eead0b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)), \n",
    "  layers.MaxPooling2D((2, 2)),\n",
    "  layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "  layers.MaxPooling2D((2, 2)),\n",
    "  layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "  layers.MaxPooling2D((2, 2)),\n",
    "  layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "  layers.MaxPooling2D((2, 2)),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(1024, activation='relu'),\n",
    "  layers.Dense(1, activation='sigmoid')  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9885420",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d7bf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(\n",
    "#    optimizer=\"adam\",\n",
    "#    loss=\"binary_crossentropy\",\n",
    "#    metrics=[\"accuracy\"],\n",
    "#)\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "optimizer=optimizers.RMSprop(learning_rate=1e-4),\n",
    "metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ba9da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    dt_images,\n",
    "    epochs=16,\n",
    "    validation_data=dt_validation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6398b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image=tf.keras.preprocessing.image.load_img(\n",
    "   \"./eu.jpg\", grayscale=False, color_mode=\"rgb\", target_size=(256,256), interpolation=\"nearest\"\n",
    ")\n",
    "input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "input_arr = np.array([input_arr])\n",
    "model.predict(input_arr)[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e845ef7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d845bde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image=tf.keras.preprocessing.image.load_img(\n",
    "   \"./eu_sem_mascara.jpg\", grayscale=False, color_mode=\"rgb\", target_size=(256,256), interpolation=\"nearest\"\n",
    ")\n",
    "input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "input_arr = np.array([input_arr])\n",
    "model.predict(input_arr)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e82663",
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372cd9e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
